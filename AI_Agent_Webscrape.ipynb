{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eb425b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!pip install langchain langgraph langsmith langchain_groq langchain_community langchain-tavily chromadb'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"!pip install langchain langgraph langsmith langchain_groq langchain_community langchain-tavily chromadb\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4761eac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51aa303c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from typing import Annotated, TypedDict, Dict, Any\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph.message import add_messages\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from chromadb.config import Settings\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89bde01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\", groq_api_key=groq_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e60eb6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def scrape_website(url: str, prompt: str = \"Extract key information in JSON format\") -> Dict[str, Any]:\n",
    "    \"\"\"Scrape a website using BeautifulSoup and proceses content with Groq's llama model\"\"\"\n",
    "    try:\n",
    "        # Fetch web page content\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        raw_content = soup.get_text(strip=True)\n",
    "        #Use groq's llama model to process the content based on the prompt\n",
    "        system_message = SystemMessage(\n",
    "            content=\"You are a function-calling AI model designed to extract structured data from text\"\n",
    "            \"Based on the user prompt, extract the requested information from the provided content\"\n",
    "            \"and return it in JSON format.\"\n",
    "        )\n",
    "        user_message = HumanMessage(\n",
    "            content=f\"Content: {raw_content[:2000]}\\n\\nPrompt: {prompt}\\n\\n Extract the requested information in JSON format.\"\n",
    "        )\n",
    "        \n",
    "        response = llm.invoke([system_message, user_message])\n",
    "        #Ensure the response is parsed as json\n",
    "        try:\n",
    "            extracted_data = json.loads(response.content)\n",
    "        except json.JSONDecodeError:\n",
    "            extracted_data = {\"raw_content\": response.content}\n",
    "        \n",
    "        return {\"data\": extracted_data, \"error\": None}\n",
    "    except Exception as e:\n",
    "        return {\"data\": None, \"error\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "662cdaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    conversation_id: str\n",
    "\n",
    "tools = [scrape_website]\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d165e24a",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Collection [conversation_history_1] already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInternalError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      2\u001b[39m chroma_client = chromadb.PersistentClient(\n\u001b[32m      3\u001b[39m     path=\u001b[33m\"\u001b[39m\u001b[33m./chroma_db\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m     settings=Settings(anonymized_telemetry=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      5\u001b[39m )\n\u001b[32m      7\u001b[39m embedding_function = embedding_functions.DefaultEmbeddingFunction()\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m collection = \u001b[43mchroma_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconversation_history_1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_function\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstore_in_chroma\u001b[39m(state: State):\n\u001b[32m     15\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Store conversation messages in chromaDB\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AI_Agent_Bootcamp_Ostad\\myenv\\Lib\\site-packages\\chromadb\\api\\client.py:183\u001b[39m, in \u001b[36mClient.create_collection\u001b[39m\u001b[34m(self, name, schema, configuration, metadata, embedding_function, data_loader, get_or_create)\u001b[39m\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m configuration_ef \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    181\u001b[39m     configuration[\u001b[33m\"\u001b[39m\u001b[33membedding_function\u001b[39m\u001b[33m\"\u001b[39m] = embedding_function\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_server\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Collection(\n\u001b[32m    193\u001b[39m     client=\u001b[38;5;28mself\u001b[39m._server,\n\u001b[32m    194\u001b[39m     model=model,\n\u001b[32m    195\u001b[39m     embedding_function=embedding_function,\n\u001b[32m    196\u001b[39m     data_loader=data_loader,\n\u001b[32m    197\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\AI_Agent_Bootcamp_Ostad\\myenv\\Lib\\site-packages\\chromadb\\api\\rust.py:242\u001b[39m, in \u001b[36mRustBindingsAPI.create_collection\u001b[39m\u001b[34m(self, name, schema, configuration, metadata, get_or_create, tenant, database)\u001b[39m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    240\u001b[39m     schema_str = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m collection = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbindings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfiguration_json_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschema_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m collection_model = CollectionModel(\n\u001b[32m    252\u001b[39m     \u001b[38;5;28mid\u001b[39m=collection.id,\n\u001b[32m    253\u001b[39m     name=collection.name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    259\u001b[39m     database=collection.database,\n\u001b[32m    260\u001b[39m )\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m collection_model\n",
      "\u001b[31mInternalError\u001b[39m: Collection [conversation_history_1] already exists"
     ]
    }
   ],
   "source": [
    "#Initialize chroma DB client\n",
    "chroma_client = chromadb.PersistentClient(\n",
    "    path=\"./chroma_db\",\n",
    "    settings=Settings(anonymized_telemetry=False)\n",
    ")\n",
    "\n",
    "embedding_function = embedding_functions.DefaultEmbeddingFunction()\n",
    "\n",
    "collection = chroma_client.create_collection(\n",
    "    name=\"conversation_history_1\",\n",
    "    embedding_function=embedding_function\n",
    ")\n",
    "\n",
    "def store_in_chroma(state: State):\n",
    "    \"\"\"Store conversation messages in chromaDB\"\"\"\n",
    "    conversation_id = state.get(\"conversation_id\", str(uuid.uuid4()))\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    #convert messages to text for embedding\n",
    "    message_texts = [f\"{msg.type}: {msg.content}\" for msg in messages]\n",
    "    \n",
    "    #Store in ChromaDB \n",
    "    collection.add(\n",
    "        documents=message_texts,\n",
    "        metadatas=[{\"conversation_id\": conversation_id, \"index\": i} for i in range(len(messages))],\n",
    "        ids=[f\"{conversation_id}_{i}\" for i in range(len(messages))]\n",
    "    )\n",
    "    \n",
    "    return conversation_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ff7a73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context(state: State) -> str:\n",
    "    \"\"\"Retrieve relevant context from chromaDB\"\"\"\n",
    "    conversation_id = state.get(\"conversation_id\", \"\")\n",
    "    last_message = state[\"messages\"][-1].content if state[\"messages\"] else \"\"\n",
    "    \n",
    "    if not conversation_id or not last_message:\n",
    "        return \"\"\n",
    "    \n",
    "    # Query chromaDB for relevant context\n",
    "    results = collection.query(\n",
    "        query_texts=[last_message],\n",
    "        n_results=3,\n",
    "        where={\"conversation_id\": conversation_id}\n",
    "    )\n",
    "    \n",
    "    #combine relevant context\n",
    "    context = \"\\n\".join([doc for doc in results['documents'][0] if doc])\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48ac17dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_calling_llm(state: State):\n",
    "    # Retrieve relevant context from chromaDB\n",
    "    context = retrieve_context(state)\n",
    "    \n",
    "    # Add context to the prompt if available\n",
    "    if context:\n",
    "        prompt = f\"Context from previous conversations: \\n{context}\\n\\nCurrent messages: \\n{state[\"messages\"]}\"\n",
    "    else:\n",
    "        prompt = state[\"messages\"]\n",
    "    \n",
    "    # Store conversation in chromaDB and get conversation_id\n",
    "    conversation_id = store_in_chroma(state)\n",
    "    \n",
    "    #Update the state with conversation_id\n",
    "    state[\"conversation_id\"] = conversation_id\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [llm_with_tools.invoke(prompt)],\n",
    "        \"conversation_id\": conversation_id\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72ca5c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.graph import START, END\n",
    "\n",
    "#initialize memory\n",
    "memory = MemorySaver()\n",
    "\n",
    "#Graph\n",
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "#Add Edges\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_conditional_edges(\n",
    "    \"tool_calling_llm\",\n",
    "    tools_condition\n",
    ")\n",
    "\n",
    "builder.add_edge(\"tool_calling_llm\", END)\n",
    "\n",
    "#Compile the graph\n",
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db26bb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "\n",
    "response = graph.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"Please tell me about todays Bangladeshi news in bengali\")],\n",
    "    \"conversation_id\": str(uuid.uuid4())\n",
    "}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c0353a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='{\"data\": {\"raw_content\": \"প্রথম আলো | বাংলা নিউজ পেপারের বর্তমান সংবাদের মূল বিবরণগুলি নিম্নরূপ:\\\\n\\\\n```json\\\\n{\\\\n  \\\\\"সর্বশেষ\\\\\": [\\\\n    {\\\\n      \\\\\"শিরোনাম\\\\\": \\\\\"জামায়াতের টিকিট কাটলে জান্নাতের টিকিট কাটা হবে, কোথায় আছে বলুক তারা: মির্জা ফখরুল\\\\\",\\\\n      \\\\\"বিবরণ\\\\\": \\\\\"প্রধানমন্ত্রী মির্জা ফখরুল ইসলাম বলেছেন, বাংলাদেশের মানুষ বোঝে ওয়ান ম্যান ওয়ান ভোট৷\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\"শিরোনাম\\\\\": \\\\\"৫.৭ থেকে যদি ৬ মাত্রার ভূমিকম্প হয়, মহাপ্রলয় হবে ঢাকায়৷\\\\\",\\\\n      \\\\\"বিবরণ\\\\\": \\\\\"আবহাওয়া অফিস বলছে, সকাল ১০টা ৩৬ মিনিট ১২ সেকেন্ডে ভূমিকম্পটি অনুভূত হয়েছে\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\"শিরোনাম\\\\\": \\\\\"ভারতে কেন্দ্রীয় ব্যাংকের কর্মকর্তা সেজে ডাকাতি, ৭ কোটি রুপি লুট\\\\\",\\\\n      \\\\\"বিবরণ\\\\\": \\\\\"ভারতের কেন্দ্রীয় ব্যাংকের কর্মকর্তা সেজে ডাকাতি করে পুলিশ ধরেছে\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\"শিরোনাম\\\\\": \\\\\"কাশ্মীরে একজন বাবা কেন গায়ে আগুন দিয়ে আত্মাহুতি দিলেন\\\\\",\\\\n      \\\\\"বিবরণ\\\\\": \\\\\"ভারত অধিকৃত কাশ্মীরে এ ধরনের প্রথম ঘটনা হচ্ছে\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\"শিরোনাম\\\\\": \\\\\"গাজীপুরে ভূমিকম্পে আহতদের বেশির ভাগই বাসায় ফিরেছেন\\\\\",\\\\n      \\\\\"বিবরণ\\\\\": \\\\\"গাজীপুরে ভূমিকম্পে আহতদের বেশির ভাগই বাসায় ফিরেছেন\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\"শিরোনাম\\\\\": \\\\\"প্রধানমন্ত্রী মোহাম্মদ শহীদুল্লাহর মৃত্যুর বার্ষিকী আজ\\\\\",\\\\n      \\\\\"বিবরণ\\\\\": \\\\\"প্রধানমন্ত্রী মোহাম্মদ শহীদুল্লাহর মৃত্যুর বার্ষিকী পালন করা হবে\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\"শিরোনাম\\\\\": \\\\\"ট্রাম্পের শুল্কের চাপে ভারতের রিলায়েন্স ইন্ডাস্ট্রিজ তেল কেনার আংশিক বন্ধ\\\\\",\\\\n      \\\\\"বিবরণ\\\\\": \\\\\"ভারতের বৃহত্তম শিল্পপ্রতিষ্ঠান রিলায়েন্স ইন্ডাস্ট্রিজ তেল কেনার আংশিক বন্ধ করেছে\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\"শিরোনাম\\\\\": \\\\\"কাশ্মীরের নিখেবার বাবা ব্যাঁচানোর জন্য টাস্কফোর্সে যোগ দিয়েছে ভারতরশিয়ার সরকার\\\\\",\\\\n      \\\\\"বিবরণ\\\\\": \\\\\"ভারতরশিয়ার সরকার কাশ্মীরের নিখেবার বাবার ব্যাঁচানোর জন্য টাস্কফোর্সে যোগ দিয়েছে\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\"শিরোনাম\\\\\": \\\\\"ভারতের প্রধানমন্ত্রী নরেন্দ্র মোদী কাশ্মীরের সরকারকে বলেছেন নিখেবার বাবাকে বের করে আনতে হবে\\\\\",\\\\n      \\\\\"বিবরণ\\\\\": \\\\\"ভারতের প্রধানমন্ত্রী নরেন্দ্র মোদী কাশ্মীরের সরকারকে বলেছেন নিখেবার বাবাকে বের করে আনতে হবে\\\\\"\\\\n    }\\\\n  ]\\\\n}\\\\n```\"}, \"error\": null}', name='scrape_website', id='f8b1be2b-0e86-4a96-848a-039d7ef3541d', tool_call_id='4mgt86d5n')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"messages\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5893f83d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
